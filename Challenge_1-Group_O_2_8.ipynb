{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Group Assignment\n",
    "### Challenge 1 | Network Intrusion Detection\n",
    "\n",
    "Group O-2-8\n",
    "\n",
    "Agenda\n",
    "1. Spark-Setup / Load Data\n",
    "2. Inspect Data\n",
    "3. Preprocess Data\n",
    "4. Create A Model\n",
    "5. Make Predictions\n",
    "6. Evaluate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Spark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/software/spark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['SPARK_HOME'])\n",
    "dataset_path=\"/home/ubuntu/challenge_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Dataset\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading\n",
    "\n",
    "Data inspection shows that the data does not have a header. Therefore we are going to use a simple for loop to assign the correct labelling to the columns. Furthermore, we are assignung the variable \"connection\" to the different types of network intrusion attacks. The connection types fall into the following categories:\n",
    "\n",
    "* DOS: denial-of-service, e.g. syn flood;\n",
    "* R2L: unauthorized access from a remote machine, e.g. guessing password;\n",
    "* U2R:  unauthorized access to local superuser (root) privileges, e.g., various buffer overflow attacks;\n",
    "* probing: surveillance and other probing, e.g., port scanning.\n",
    "* normal: no attack was identified\n",
    "\n",
    "#### 1.1.1 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"file://\"+dataset_path+\"full.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features=[\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\"dst_bytes\", \\\n",
    "          \"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\", \\\n",
    "          \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\", \\\n",
    "          \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\", \\\n",
    "          \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\\\n",
    "          \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \\\n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\", \\\n",
    "          \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\\\n",
    "          \"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "target=[\"connection\"]\n",
    "\n",
    "fieldnames=features+target\n",
    "\n",
    "rawnames=df.schema.names\n",
    "\n",
    "# Create a small function\n",
    "def updateColNames(df,oldnames,newnames):\n",
    "    for i in range(len(newnames)):\n",
    "        df=df.withColumnRenamed(oldnames[i], newnames[i])\n",
    "    return df\n",
    "\n",
    "df=updateColNames(df,rawnames,fieldnames)\n",
    "\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Creating new attack variable 'label'\n",
    "\n",
    "Regarding the scope of this assignment, there is no need to classify attack types into the correct group (i.e probing or DOS). We simply have to identify whether or not an attack is taking place. Thus, we are creating a new boolean column 'lable':\n",
    "\n",
    "* Assign the value '0' for no attack (=normal)\n",
    "* Assign the value '1' for attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1|3925650|\n",
      "|    0| 972781|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a Boolean column for attack (=1) or normal (=0)\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn('label', when(df[\"connection\"] == 'normal.', 0).otherwise(1))\n",
    "\n",
    "df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Loading Test Data\n",
    "\n",
    "We have to repeat the same process for the test data:\n",
    "\n",
    "* Assign column names\n",
    "* Create new column 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = spark.read \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"file://\"+dataset_path+\"corrected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test=[\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\",\"dst_bytes\", \\\n",
    "          \"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\", \\\n",
    "          \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\", \\\n",
    "          \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\", \\\n",
    "          \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\\\n",
    "          \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \\\n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\", \\\n",
    "          \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\\\n",
    "          \"dst_host_srv_rerror_rate\"]\n",
    "\n",
    "target_test=[\"connection\"]\n",
    "\n",
    "fieldnames_test=features_test+target_test\n",
    "\n",
    "rawnames_test=df_test.schema.names\n",
    "\n",
    "# Create a small function\n",
    "def updateColNames_test(df_test,oldnames,newnames):\n",
    "    for i in range(len(newnames)):\n",
    "        df_test=df_test.withColumnRenamed(oldnames[i], newnames[i])\n",
    "    return df_test\n",
    "\n",
    "df_test=updateColNames(df_test,rawnames,fieldnames)\n",
    "\n",
    "# df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|250436|\n",
      "|    0| 60593|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a Boolean column for attack (=1) or normal (=0)\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_test = df_test.withColumn('label', when(df_test[\"connection\"] == 'normal.', 0).otherwise(1))\n",
    "\n",
    "df_test.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Inspection\n",
    "\n",
    "\n",
    "* How many records do we have?\n",
    "* What is the schema of our data?\n",
    "* Is it numerical , is it categorical?\n",
    "* Visualize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb. of records  : 4898431\n"
     ]
    }
   ],
   "source": [
    "# Print the number of records in the data frame\n",
    "print('Nb. of records  : %d' % df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+--------------------+--------------------+\n",
      "|summary|         duration|         src_bytes|         dst_bytes|      wrong_fragment|   num_failed_logins|\n",
      "+-------+-----------------+------------------+------------------+--------------------+--------------------+\n",
      "|  count|          4898431|           4898431|           4898431|             4898431|             4898431|\n",
      "|   mean|48.34243046395876|1834.6211752293746|1093.6228137132073|6.487791703098401E-4|3.205107921291532E-5|\n",
      "| stddev|723.3298112546812| 941431.0744911365| 645012.3337425214| 0.04285433675493731|0.007299407575927214|\n",
      "|    min|                0|                 0|                 0|                   0|                   0|\n",
      "|    max|            58329|        1379963888|        1309937401|                   3|                   5|\n",
      "+-------+-----------------+------------------+------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('duration','src_bytes','dst_bytes','wrong_fragment','num_failed_logins').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploring numercial variables\n",
    "\n",
    "In total, there are 28 numercial variables in our dataset:\n",
    "\n",
    "* XX continous 22)\n",
    "* XX boolean (6)\n",
    "\n",
    "We are using agg() operations in order to compare means between attack and non-attack networks and receive a couple of insights:\n",
    "\n",
    "* Duration: the mean duration of normal connection is longer\n",
    "* Dst_bytes: the mean number of data bytes from destination to source is 6x greater\n",
    "* Hot: the mean number of 'hot' indiactors is 15x smaller for attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Compare averages of numcerical features between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|     avg(duration)|\n",
      "+-----+------------------+\n",
      "|    0|217.82472416710442|\n",
      "|    1|6.3445052411702525|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some stats on numerical features\n",
    "df.groupBy('label').agg({'duration': 'mean'}).orderBy(\"avg(duration)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|    avg(src_bytes)|\n",
      "+-----+------------------+\n",
      "|    1| 1923.030449734439|\n",
      "|    0|1477.8462500809535|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some stats on numerical features\n",
    "df.groupBy('label').agg({'src_bytes': 'mean'}).orderBy(\"avg(src_bytes)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|    avg(dst_bytes)|\n",
      "+-----+------------------+\n",
      "|    0|3234.6501113816985|\n",
      "|    1| 563.0735605568505|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('label').agg({'dst_bytes': 'mean'}).orderBy(\"avg(dst_bytes)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label| avg(wrong_fragment)|\n",
      "+-----+--------------------+\n",
      "|    1|8.095474634773859E-4|\n",
      "|    0|                 0.0|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some stats on numerical features\n",
    "df.groupBy('label').agg({'wrong_fragment': 'mean'}).orderBy(\"avg(wrong_fragment)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            avg(hot)|\n",
      "+-----+--------------------+\n",
      "|    0| 0.04953530136793379|\n",
      "|    1|0.003244812960910932|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some stats on numerical features\n",
    "df.groupBy('label').agg({'hot': 'mean'}).orderBy(\"avg(hot)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------+\n",
      "|label|avg(num_failed_logins)|\n",
      "+-----+----------------------+\n",
      "|    0|   9.86861379899484E-5|\n",
      "|    1|  1.553882796479563...|\n",
      "+-----+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some stats on numerical features\n",
    "df.groupBy('label').agg({'num_failed_logins': 'mean'}).orderBy(\"avg(num_failed_logins)\", ascending = False).show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Exploring the categorical variables\n",
    "\n",
    "Again, we are using grouby() commands to explore the categorical variables and their count().\n",
    "\n",
    "* protocol_type (3 distinct types)\n",
    "* service       (70 distinct types)\n",
    "* flag          (11 distinct types)\n",
    "* connection    (21 distinct types)\n",
    "\n",
    "in term of the number of categories and count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|protocol_type|  count|\n",
      "+-------------+-------+\n",
      "|          tcp|1870598|\n",
      "|          udp| 194288|\n",
      "|         icmp|2833545|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many distict flags we have\n",
    "df.groupby('protocol_type').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  service|count|\n",
      "+---------+-----+\n",
      "|   telnet| 4277|\n",
      "|      ftp| 5214|\n",
      "|     auth| 3382|\n",
      "| iso_tsap| 1052|\n",
      "|   systat| 1056|\n",
      "|     name| 1067|\n",
      "|  sql_net| 1052|\n",
      "|    ntp_u| 3833|\n",
      "|      X11|  135|\n",
      "|    pop_3| 1981|\n",
      "|     ldap| 1041|\n",
      "|  discard| 1059|\n",
      "|   tftp_u|    3|\n",
      "|   Z39_50| 1078|\n",
      "|  daytime| 1056|\n",
      "| domain_u|57782|\n",
      "|    login| 1045|\n",
      "|     smtp|96554|\n",
      "|http_2784|    1|\n",
      "|      mtp| 1076|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many distict services we have\n",
    "df.groupby('service').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|  flag|  count|\n",
      "+------+-------+\n",
      "|RSTOS0|    122|\n",
      "|    S3|     50|\n",
      "|    SF|3744328|\n",
      "|    S0| 869829|\n",
      "|   OTH|     57|\n",
      "|   REJ| 268874|\n",
      "|  RSTO|   5344|\n",
      "|  RSTR|   8094|\n",
      "|    SH|   1040|\n",
      "|    S2|    161|\n",
      "|    S1|    532|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many distict flags we have\n",
    "df.groupby('flag').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|      connection|  count|\n",
      "+----------------+-------+\n",
      "|          smurf.|2807886|\n",
      "|        neptune.|1072017|\n",
      "|         normal.| 972781|\n",
      "|          satan.|  15892|\n",
      "|        ipsweep.|  12481|\n",
      "|      portsweep.|  10413|\n",
      "|           nmap.|   2316|\n",
      "|           back.|   2203|\n",
      "|    warezclient.|   1020|\n",
      "|       teardrop.|    979|\n",
      "|            pod.|    264|\n",
      "|   guess_passwd.|     53|\n",
      "|buffer_overflow.|     30|\n",
      "|           land.|     21|\n",
      "|    warezmaster.|     20|\n",
      "|           imap.|     12|\n",
      "|        rootkit.|     10|\n",
      "|     loadmodule.|      9|\n",
      "|      ftp_write.|      8|\n",
      "|       multihop.|      7|\n",
      "|            phf.|      4|\n",
      "|           perl.|      3|\n",
      "|            spy.|      2|\n",
      "+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('connection').count()\\\n",
    "    .orderBy('count', ascending =False)\\\n",
    "    .show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.3 Exploring data visually (@Adolfo)\n",
    "\n",
    "tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3a. Create a in-memory DataFrame \n",
    "# df2.registerTempTable(\"network_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data\n",
    "\n",
    "The data inspetion shows that our dataset contains three categorical variables:\n",
    "\n",
    "* protocol_type\n",
    "* service\n",
    "* flag\n",
    "\n",
    "We are going to use StringIndexer, OneHotEncoder, Vector Assembler and a Pipeline to compute feature transformation.\n",
    "\n",
    "* **StringIndexer**: converts a single column to an index column (similar to a factor column in R)\n",
    "* **OneHotEncoder**: One-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. This encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features.\n",
    "* **VectorAssembler**: A transformer that combines a given list of columns into a single vector column.\n",
    "* **Pipelines**: Facilitates the creation, tuning, and inspection of practical ML workflows. A Spark Pipeline is specified as a sequence of stages, and each stage is either a Transformer or an Estimator. These stages are run in order, and the input DataFrame is transformed as it passes through each stage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "categoricalColumns = [ \\\n",
    "           \"protocol_type\", \"service\", \"flag\"]\n",
    "\n",
    "stages = [] # stages in our Pipeline\n",
    "for col in categoricalColumns:\n",
    "  \n",
    "  # Category Indexing with StringIndexer\n",
    "  indexer = StringIndexer(inputCol=col, outputCol=col+\"_index\")\n",
    "   \n",
    "  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "  # encoder = OneHotEncoder(inputCol=col+\"_index\", outputCol=col+\"_vector\")\n",
    "  \n",
    "  # Add stages.  These are not run here, but will run all at once later on.\n",
    "  stages += [indexer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 VectorAssembler \n",
    "\n",
    "This output will include both the numeric columns and the one-hot encoded binary vector columns in our dataset.\n",
    "\n",
    "We are not going to use all of the numeric features from the dataset. The most important features have been identified while inspecting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type_index', 'service_index', 'flag_index', 'duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent']\n"
     ]
    }
   ],
   "source": [
    "# Transform all numerical features into a vector using VectorAssembler\n",
    "\n",
    "numericCols_model = [\"duration\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\"]\n",
    "\n",
    "assemblerInputs = [ col + \"_index\" for col in categoricalColumns ] + numericCols_model\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "\n",
    "print(assemblerInputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Checking the stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage number 0 protocol_type_index\n",
      "stage number 1 service_index\n",
      "stage number 2 flag_index\n",
      "stage number 3 features\n"
     ]
    }
   ],
   "source": [
    "# Check the stages of our pipeline\n",
    "n=0\n",
    "for s in stages:\n",
    "    print('stage number %d %s' %(n,s.getOutputCol()))\n",
    "    n+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Model \n",
    " * Create the model\n",
    " * Split data into train and test data\n",
    " * Train the model with train data\n",
    " * Test model predictions with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Create Pipleline\n",
    "\n",
    "Group together the stages we defined (feature transformations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "transformer = pipeline.fit(df)\n",
    "transformed_df = transformer.transform(df)\n",
    "\n",
    "# Focus on the relevant columns and define dataset\n",
    "selection = [\"label\", \"features\"] # + assemblerInputs     # \"duration\", \"src_bytes\"\n",
    "dataset = transformed_df.select(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 236.0, 1228.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 233.0, 2032.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 239.0, 486.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  (1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...\n",
       "1      0  (1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...\n",
       "2      0  (1.0, 2.0, 0.0, 0.0, 236.0, 1228.0, 0.0, 0.0, ...\n",
       "3      0  (1.0, 2.0, 0.0, 0.0, 233.0, 2032.0, 0.0, 0.0, ...\n",
       "4      0  (1.0, 2.0, 0.0, 0.0, 239.0, 486.0, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Splitting dataset into train and test\n",
    "\n",
    "* 70% train | 30% test\n",
    "* Setting a seed to esnure reproducability of the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training records : 3427798\n",
      "Test records : 1470633 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, features: vector]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data, test_data) = dataset.randomSplit([0.7, 0.3], seed = 123)\n",
    "print('Training records : %d' % train_data.count())\n",
    "print('Test records : %d ' % test_data.count())\n",
    "train_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Create a Logisitc Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model with Training Data\n",
    "model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: int, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on test data using the transform() method. Feature have been specified earlier.\n",
    "predictions = model.transform(test_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[2.26141401484, -2.26141401484]</td>\n",
       "      <td>[0.905630547549, 0.0943694524514]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[2.31846268861, -2.31846268861]</td>\n",
       "      <td>[0.910394611644, 0.0896053883558]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[2.31846268861, -2.31846268861]</td>\n",
       "      <td>[0.910394611644, 0.0896053883558]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[-1.89255377757, 1.89255377757]</td>\n",
       "      <td>[0.130953563468, 0.869046436532]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n",
       "      <td>[-1.89255377757, 1.89255377757]</td>\n",
       "      <td>[0.130953563468, 0.869046436532]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                       features  \\\n",
       "0      0  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n",
       "1      0  (1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n",
       "2      0  (1.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n",
       "3      0  (1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n",
       "4      0  (1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)   \n",
       "\n",
       "                     rawPrediction                        probability  \\\n",
       "0  [2.26141401484, -2.26141401484]  [0.905630547549, 0.0943694524514]   \n",
       "1  [2.31846268861, -2.31846268861]  [0.910394611644, 0.0896053883558]   \n",
       "2  [2.31846268861, -2.31846268861]  [0.910394611644, 0.0896053883558]   \n",
       "3  [-1.89255377757, 1.89255377757]   [0.130953563468, 0.869046436532]   \n",
       "4  [-1.89255377757, 1.89255377757]   [0.130953563468, 0.869046436532]   \n",
       "\n",
       "   prediction  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         1.0  \n",
       "4         1.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See model's predictions and probabilities of each prediction class\n",
    "# You can select any columns in the above schema to view as well. \n",
    "# For example's sake we will choose age & occupation\n",
    "#selected = predictions.select(\"label\", \"prediction\", \"duration\",\"src_bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction  duration  src_bytes\n",
       "0      0         1.0         0         30\n",
       "1      0         1.0         0         30\n",
       "2      0         1.0         0         30\n",
       "3      0         1.0         0         30\n",
       "4      0         1.0         0         30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics:\n",
    "\n",
    "Binary classifiers are used to separate the elements of a given dataset into one of two possible groups (e.g. attack or no attack)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is : 0.942774\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "score = evaluator.evaluate(predictions)\n",
    "print('Score is : %03f' % score )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Model Selection\n",
    "\n",
    "** READ THIS : ** : https://spark.apache.org/docs/2.2.1/ml-tuning.html\n",
    "\n",
    "Model selection consists in using data to find the best model or parameters for a given task.\n",
    "\n",
    " * Inspect available parameters for tuning\n",
    " * Use CrossValidation or TrainValidationSplit for parameter tuning\n",
    " * Both requires the following inputs:\n",
    "    *  Estimator: algorithm or Pipeline to tune\n",
    "    *  Set of ParamMaps: parameters to choose from, sometimes called a “parameter grid” to search over\n",
    "    *  Evaluator: metric to measure how well a fitted Model does on held-out test data\n",
    "\n",
    "* At a high level, these model selection tools work as follows:\n",
    "\n",
    "   *  They split the input data into separate training and test datasets.\n",
    "   * For each (training, test) pair, they iterate through the set of ParamMaps:\n",
    "   * For each ParamMap, they fit the Estimator using those parameters, get the fitted Model, and evaluate the Model’s performance using the Evaluator.\n",
    "   \n",
    "*  They finally select the Model produced by the best-performing set of parameters.\n",
    "\n",
    "** An interesting blog on parameter tuning ** :https://www.oreilly.com/ideas/big-datas-biggest-secret-hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regParam: regularization parameter (>= 0). (default: 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(lr.explainParam(\"regParam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(lr.explainParam(\"elasticNetParam\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Parameters Grid for Cross Validation\n",
    "we will create a model for each combination of parameters in the grid specified and evaluate its result\n",
    "\n",
    "We use :\n",
    " 3 regularization param values (regParam)\n",
    " 3 values for maximum nb of iterations\n",
    " 3 values for elasticNetParam\n",
    " The grid will have 3 x 3 x 3 = 27 parameter settings to choose from. \n",
    "\n",
    "\n",
    " Regularization Parameter: \n",
    "\n",
    " (intuitively) is a penalty against complexity. \n",
    " A bigger regParam penalizes \"large\" weight coefficients ,i.e, \n",
    " tries to avoid our model model picking up \"noise,\" or \"deducting a pattern where there is none.\"\n",
    " tries to avoid OVERFITTING\n",
    "\n",
    " ElasticNetParam:\n",
    " read this : https://en.wikipedia.org/wiki/Elastic_net_regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [1, 5, 10])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-fold CrossValidator\n",
    "\n",
    "# numFolds determines the number of train/test dataset pairs used in the cross-validation\n",
    "# The cross validation will compute the  average of the evaluation metrics produced by the n models\n",
    "# by fitting the Estimator on the 3 different (training, test) dataset pairs.\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "# this may take some of time (depends on the amount of models that we're creating and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(test_data)\n",
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "best_score=evaluator.evaluate(predictions)\n",
    "# print('Best model score : %03f' % best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predicting test data\n",
    "\n",
    "We are using the previously created pipleline on the corrected dataset: df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|250436|\n",
      "|    0| 60593|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer_test = pipeline.fit(df_test)\n",
    "transformed_df_test = transformer_test.transform(df_test)\n",
    "\n",
    "# Keep relevant columns\n",
    "selection_test = [\"label\", \"features\"] #+ assemblerInputs #  \"duration\", \"src_bytes\"\n",
    "dataset_test = transformed_df_test.select(selection_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "1      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "2      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "3      1  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "4      1  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions_test = cvModel.transform(dataset)        # WE CAN EITHER USE MODEL OR CVMODEL\n",
    "# cvModel uses the best model found from the Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 236.0, 1228.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 233.0, 2032.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 239.0, 486.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  (1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...\n",
       "1      0  (1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...\n",
       "2      0  (1.0, 2.0, 0.0, 0.0, 236.0, 1228.0, 0.0, 0.0, ...\n",
       "3      0  (1.0, 2.0, 0.0, 0.0, 233.0, 2032.0, 0.0, 0.0, ...\n",
       "4      0  (1.0, 2.0, 0.0, 0.0, 239.0, 486.0, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...</td>\n",
       "      <td>[2.26946088401, -2.26946088401]</td>\n",
       "      <td>[0.906316022911, 0.0936839770893]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2.27248203687, -2.27248203687]</td>\n",
       "      <td>[0.906572226116, 0.0934277738836]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features  \\\n",
       "0      0  (1.0, 2.0, 0.0, 0.0, 215.0, 45076.0, 0.0, 0.0,...   \n",
       "1      0  (1.0, 2.0, 0.0, 0.0, 162.0, 4528.0, 0.0, 0.0, ...   \n",
       "\n",
       "                     rawPrediction                        probability  \\\n",
       "0  [2.26946088401, -2.26946088401]  [0.906316022911, 0.0936839770893]   \n",
       "1  [2.27248203687, -2.27248203687]  [0.906572226116, 0.0934277738836]   \n",
       "\n",
       "   prediction  \n",
       "0         0.0  \n",
       "1         0.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "1      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "2      0  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "3      1  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)\n",
       "4      1  (2.0, 1.0, 0.0, 0.0, 105.0, 146.0, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model score : 0.942685\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model\n",
    "best_score_test = evaluator.evaluate(predictions_test)\n",
    "print('Best model score : %03f' % best_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
